{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshildarji/Machine-Learning/blob/master/Transformers/EsperBERTo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### This is from a tutorial from [Hugging Face](https://huggingface.co/blog/how-to-train) 🤗."
      ],
      "metadata": {
        "id": "9hWW0Dm2zCQU"
      },
      "id": "9hWW0Dm2zCQU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get dataset and required libraries"
      ],
      "metadata": {
        "id": "AnVxb0zdzYtk"
      },
      "id": "AnVxb0zdzYtk"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d703bdee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d703bdee",
        "outputId": "b9fb00f8-10d3-476d-8fc4-4558b4d05fab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-06 13:06:10--  https://cdn-datasets.huggingface.co/EsperBERTo/data/oscar.eo.txt\n",
            "Resolving cdn-datasets.huggingface.co (cdn-datasets.huggingface.co)... 54.192.20.121, 54.192.20.22, 54.192.20.117, ...\n",
            "Connecting to cdn-datasets.huggingface.co (cdn-datasets.huggingface.co)|54.192.20.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 312733741 (298M) [text/plain]\n",
            "Saving to: ‘oscar.eo.txt’\n",
            "\n",
            "oscar.eo.txt        100%[===================>] 298.25M  22.0MB/s    in 17s     \n",
            "\n",
            "2022-02-06 13:06:29 (17.2 MB/s) - ‘oscar.eo.txt’ saved [312733741/312733741]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -c https://cdn-datasets.huggingface.co/EsperBERTo/data/oscar.eo.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "43e1d826",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43e1d826",
        "outputId": "31a72c41-c515-477c-8bcd-f270773b2641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.7.0\n",
            "Uninstalling tensorflow-2.7.0:\n",
            "  Successfully uninstalled tensorflow-2.7.0\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-qyyui4gf\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-qyyui4gf\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0.dev0) (4.10.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0.dev0) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0.dev0) (3.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0.dev0) (21.3)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 69.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0.dev0) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 83.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.17.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17.0.dev0) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.17.0.dev0) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.17.0.dev0) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.17.0.dev0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.17.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.17.0.dev0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.17.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.17.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.17.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.17.0.dev0) (1.1.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.17.0.dev0-py3-none-any.whl size=3616693 sha256=5d1d808546093d6980985358a83280eb934cd128cfa34ba96c278ae6495fda08\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-02eie0tc/wheels/35/2e/a7/d819e3310040329f0f47e57c9e3e7a7338aa5e74c49acfe522\n",
            "Successfully built transformers\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.17.0.dev0\n",
            "tokenizers                    0.11.4\n",
            "transformers                  4.17.0.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y tensorflow\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip list | grep -E 'transformers|tokenizers'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train a tokenizer"
      ],
      "metadata": {
        "id": "v757B3G9zfPQ"
      },
      "id": "v757B3G9zfPQ"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "27c7e9e0",
      "metadata": {
        "id": "27c7e9e0"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from tokenizers import ByteLevelBPETokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ba0eeb78",
      "metadata": {
        "id": "ba0eeb78"
      },
      "outputs": [],
      "source": [
        "path = [str(x) for x in Path('.').glob('**/*.txt')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "918db02a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "918db02a",
        "outputId": "95c624e7-b5ee-4512-f038-8d046ec339e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6min 2s, sys: 4.78 s, total: 6min 7s\n",
            "Wall time: 1min 46s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "tokenizer.train(files=path, vocab_size=52_000, min_frequency=2, special_tokens=[\n",
        "    '<s>',\n",
        "    '<pad>',\n",
        "    '</s>',\n",
        "    '<unk>',\n",
        "    '<mask>',\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save `tokenizer`"
      ],
      "metadata": {
        "id": "LI_r9HzuzkqE"
      },
      "id": "LI_r9HzuzkqE"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "872f4235",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "872f4235",
        "outputId": "0774c542-8dd9-4add-8777-8de74a02b001"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['EsperBERTo/vocab.json', 'EsperBERTo/merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "!mkdir EsperBERTo\n",
        "tokenizer.save_model('EsperBERTo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dcbb9e0f",
      "metadata": {
        "id": "dcbb9e0f"
      },
      "outputs": [],
      "source": [
        "from tokenizers.implementations import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ab132b63",
      "metadata": {
        "id": "ab132b63"
      },
      "outputs": [],
      "source": [
        "tokenizer = ByteLevelBPETokenizer('./EsperBERTo/vocab.json', './EsperBERTo/merges.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d17cf14f",
      "metadata": {
        "id": "d17cf14f"
      },
      "outputs": [],
      "source": [
        "tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "    ('</s>', tokenizer.token_to_id('</s>')), \n",
        "    ('<s>', tokenizer.token_to_id('<s>')),\n",
        ")\n",
        "tokenizer.enable_truncation(max_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "374eca73",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "374eca73",
        "outputId": "aaf1ca22-9267-4ce6-a064-1913ec5066e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoding(num_tokens=7, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "tokenizer.encode('Mi estas Julien.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8989c7b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8989c7b4",
        "outputId": "f81b610a-6f86-4469-c8bc-579bf01bacba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', 'Mi', 'Ġestas', 'ĠJuli', 'en', '.', '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "tokenizer.encode('Mi estas Julien.').tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train language model"
      ],
      "metadata": {
        "id": "BTxjLGhezxUR"
      },
      "id": "BTxjLGhezxUR"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "98f60f09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98f60f09",
        "outputId": "a6e08ff0-53c1-4b42-8cb4-6e91e025f5a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb  6 13:08:56 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "619067dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "619067dc",
        "outputId": "2c99e616-a767-4e69-c2fa-d060b6d63e81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "80b2a0d9",
      "metadata": {
        "id": "80b2a0d9"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaConfig\n",
        "\n",
        "config = RobertaConfig(\n",
        "    vocab_size=52_000, \n",
        "    max_position_embeddings=514, \n",
        "    num_attention_heads=12, \n",
        "    num_hidden_layers=6, \n",
        "    type_vocab_size=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9d544bb2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d544bb2",
        "outputId": "2e263d1b-3b04-410b-b31e-d6dbd4bdfba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "file ./EsperBERTo/config.json not found\n",
            "file ./EsperBERTo/config.json not found\n"
          ]
        }
      ],
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained('./EsperBERTo', max_len=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "93110145",
      "metadata": {
        "id": "93110145"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaForMaskedLM\n",
        "\n",
        "model = RobertaForMaskedLM(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "1fe072eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fe072eb",
        "outputId": "7134a165-8a8d-429e-ca09-3b55680a93d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83504416"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "model.num_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "70ae80cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70ae80cd",
        "outputId": "bc6bc441-849d-4392-9a9b-05e47abfaadc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:125: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5min, sys: 7.35 s, total: 5min 7s\n",
            "Wall time: 1min 48s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from transformers import LineByLineTextDataset\n",
        "\n",
        "dataset = LineByLineTextDataset(tokenizer=tokenizer, file_path='./oscar.eo.txt', block_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3803a00f",
      "metadata": {
        "id": "3803a00f"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collector = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "12e255e9",
      "metadata": {
        "id": "12e255e9"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./EsperBERTo/', \n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_gpu_train_batch_size=64,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collector,\n",
        "    train_dataset=dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "0d7f5a9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0d7f5a9c",
        "outputId": "6bfbb6e8-4a91-4bf8-c094-65213174b63c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 974545\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 15228\n",
            "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13421' max='15228' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13421/15228 2:30:45 < 20:18, 1.48 it/s, Epoch 0.88/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>7.862700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>7.261100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>7.076100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.971700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>6.873700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.791800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>6.756900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>6.707900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>6.651100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>6.582700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>6.545500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>6.441700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>6.341700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>6.214100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>6.083900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>5.959700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>5.856500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>5.762200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>5.646100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>5.553300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>5.501300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>5.445800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>5.383600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>5.344100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>5.315700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>5.278800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./EsperBERTo/checkpoint-10000\n",
            "Configuration saved in ./EsperBERTo/checkpoint-10000/config.json\n",
            "Model weights saved in ./EsperBERTo/checkpoint-10000/pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='15228' max='15228' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15228/15228 2:51:05, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>7.862700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>7.261100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>7.076100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>6.971700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>6.873700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>6.791800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>6.756900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>6.707900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>6.651100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>6.582700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>6.545500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>6.441700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>6.341700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>6.214100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>6.083900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>5.959700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>5.856500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>5.762200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>5.646100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>5.553300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>5.501300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>5.445800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>5.383600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>5.344100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>5.315700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>5.278800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>5.239400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>5.251300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>5.212600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>5.226000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2h 48min 48s, sys: 3min 2s, total: 2h 51min 50s\n",
            "Wall time: 2h 51min 6s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=15228, training_loss=6.0911533925863335, metrics={'train_runtime': 10266.2503, 'train_samples_per_second': 94.927, 'train_steps_per_second': 1.483, 'total_flos': 3.231256266892493e+16, 'train_loss': 6.0911533925863335, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "%%time\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save model"
      ],
      "metadata": {
        "id": "4WdmzNOPz6pY"
      },
      "id": "4WdmzNOPz6pY"
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('./EsperBERTo/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sItKIgMqxR0l",
        "outputId": "c454696b-61a5-40ce-9c7d-43fa2e45e516"
      },
      "id": "sItKIgMqxR0l",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./EsperBERTo/\n",
            "Configuration saved in ./EsperBERTo/config.json\n",
            "Model weights saved in ./EsperBERTo/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test language model"
      ],
      "metadata": {
        "id": "oxcg9MJ5z8Ub"
      },
      "id": "oxcg9MJ5z8Ub"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "z9mPcfmpxj_B"
      },
      "id": "z9mPcfmpxj_B",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fill_mask = pipeline(\n",
        "    'fill-mask',\n",
        "    model='./EsperBERTo/',\n",
        "    tokenizer='./EsperBERTo/'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsU7lHG0xpJO",
        "outputId": "24b7d93c-ec8c-4196-a073-31f97dd62098"
      },
      "id": "VsU7lHG0xpJO",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file ./EsperBERTo/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./EsperBERTo/\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading configuration file ./EsperBERTo/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./EsperBERTo/\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading weights file ./EsperBERTo/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForMaskedLM.\n",
            "\n",
            "All the weights of RobertaForMaskedLM were initialized from the model checkpoint at ./EsperBERTo/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForMaskedLM for predictions without further training.\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file ./EsperBERTo/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./EsperBERTo/\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "Didn't find file ./EsperBERTo/tokenizer.json. We won't load it.\n",
            "Didn't find file ./EsperBERTo/added_tokens.json. We won't load it.\n",
            "Didn't find file ./EsperBERTo/special_tokens_map.json. We won't load it.\n",
            "Didn't find file ./EsperBERTo/tokenizer_config.json. We won't load it.\n",
            "loading file ./EsperBERTo/vocab.json\n",
            "loading file ./EsperBERTo/merges.txt\n",
            "loading file None\n",
            "loading file None\n",
            "loading file None\n",
            "loading file None\n",
            "loading configuration file ./EsperBERTo/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./EsperBERTo/\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading configuration file ./EsperBERTo/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"./EsperBERTo/\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0.dev0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fill_mask('La suno <mask>.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hwk1-HlCx150",
        "outputId": "e94ca240-55ba-418f-d9ac-159011a25236"
      },
      "id": "Hwk1-HlCx150",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.0064928182400763035,\n",
              "  'sequence': 'La suno estas.',\n",
              "  'token': 316,\n",
              "  'token_str': ' estas'},\n",
              " {'score': 0.005978148430585861,\n",
              "  'sequence': 'La suno okuloj.',\n",
              "  'token': 2574,\n",
              "  'token_str': ' okuloj'},\n",
              " {'score': 0.003927275072783232,\n",
              "  'sequence': 'La suno kapon.',\n",
              "  'token': 4094,\n",
              "  'token_str': ' kapon'},\n",
              " {'score': 0.0035268838983029127,\n",
              "  'sequence': 'La suno vizaĝo.',\n",
              "  'token': 4051,\n",
              "  'token_str': ' vizaĝo'},\n",
              " {'score': 0.0031614797189831734,\n",
              "  'sequence': 'La suno suno.',\n",
              "  'token': 3938,\n",
              "  'token_str': ' suno'}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fill_mask(\"Jen la komenco de bela <mask>.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHAWXLSVx8XQ",
        "outputId": "e9f3b104-227a-4f7a-d9b8-2b4ba6b2fbdf"
      },
      "id": "pHAWXLSVx8XQ",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.010006673634052277,\n",
              "  'sequence': 'Jen la komenco de bela tago.',\n",
              "  'token': 1633,\n",
              "  'token_str': ' tago'},\n",
              " {'score': 0.008677692152559757,\n",
              "  'sequence': 'Jen la komenco de bela tempo.',\n",
              "  'token': 1021,\n",
              "  'token_str': ' tempo'},\n",
              " {'score': 0.008421780541539192,\n",
              "  'sequence': 'Jen la komenco de bela mondo.',\n",
              "  'token': 945,\n",
              "  'token_str': ' mondo'},\n",
              " {'score': 0.006265346426516771,\n",
              "  'sequence': 'Jen la komenco de bela jaroj.',\n",
              "  'token': 757,\n",
              "  'token_str': ' jaroj'},\n",
              " {'score': 0.005135939922183752,\n",
              "  'sequence': 'Jen la komenco de bela vivo.',\n",
              "  'token': 1160,\n",
              "  'token_str': ' vivo'}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "EsperBERTo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}